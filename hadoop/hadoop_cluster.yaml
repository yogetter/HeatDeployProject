heat_template_version: ocata

parameters:
  key_name:
    type: string
  flavor:
    type: string
  image:
    type: string
  private_net:
    type: string
  slave_count:
    type: number
    label: instances count
    description: Number of instances
  security_group:
    type: string


resources:

################### Get Hadoop & install java ####################
  pre_install_master:
    type: OS::Heat::SoftwareConfig
    properties:
      inputs:
        - name: master_ip
        - name: slave_ip
      group: script
      config: |
        #!/bin/bash
        echo ${master_ip} hadoop-master >> /etc/hosts
        echo ${slave_ip} >> /root/slave_ip
        index=0
        for i in $(cat /root/slave_ip | grep -o "[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}")
        do
             index=$((index+1))
             echo "$i hadoop-slave$index" >> /etc/hosts
        done
        dnf install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64 wget 
        sed -i '1i export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-7.b13.fc27.x86_64/jre/' /root/.bashrc
        wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.2/hadoop-2.7.2.tar.gz
        tar -xf hadoop-2.7.2.tar.gz -C /opt/
  pre_install_slave:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        dnf install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64 wget 
        sed -i '1i export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-7.b13.fc27.x86_64/jre/' /root/.bashrc
################### Get Hadoop & install java ####################

################### Hadoop cluster set ####################
  set_hadoop:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        echo -e "<?xml version=\"1.0\" encoding=\"UTF-8\"?> \n\
        <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> \n\
        <configuration> \n\
           <property> \n\
               <name>fs.defaultFS</name> \n\
               <value>hdfs://hadoop-master:9000</value> \n\
           </property> \n\
            <property> \n\
               <name>hadoop.tmp.dir</name> \n\
               <value>/hadoop</value> \n\
           </property> \n\
        </configuration>" > /opt/hadoop-2.7.2/etc/hadoop/core-site.xml
        echo -e "<?xml version=\"1.0\" encoding=\"UTF-8\"?> \n\
        <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> \n\
        <configuration> \n\
           <property> \n\
               <name>dfs.namenode.secondary.http-address</name> \n\
               <value>hadoop-master:50090</value> \n\
           </property> \n\
           <property> \n\
               <name>dfs.namenode.secondary.https-address</name> \n\
               <value>hadoop-master:50091</value> \n\
           </property> \n\
        </configuration>" > /opt/hadoop-2.7.2/etc/hadoop/hdfs-site.xml
        echo -e "<?xml version=\"1.0\" encoding=\"UTF-8\"?> \n\
        <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?> \n\
        <configuration> \n\
           <property> \n\
               <name>yarn.nodemanager.aux-services</name> \n\
               <value>mapreduce_shuffle</value> \n\
           </property> \n\
           <property> \n\
               <name>yarn.resourcemanager.hostname</name> \n\
               <value>hadoop-master</value> \n\
           </property> \n\
        </configuration>" > /opt/hadoop-2.7.2/etc/hadoop/yarn-site.xml
        echo -e "<?xml version=\"1.0\" encoding=\"UTF-8\"?> \n\
        <configuration> \n\
           <property> \n\
               <name>mapreduce.framework.name</name> \n\
               <value>yarn</value> \n\
           </property> \n\
        </configuration>" > /opt/hadoop-2.7.2/etc/hadoop/mapred-site.xml

  set_slaves:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        index=0
        echo "" > /opt/hadoop-2.7.2/etc/hadoop/slaves
        for i in $(cat /root/slave_ip | grep -o "[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}")
        do
             index=$((index+1))
             echo hadoop-slave$index >> /opt/hadoop-2.7.2/etc/hadoop/slaves
        done
        index=0
        for i in $(cat /root/slave_ip | grep -o "[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}")
        do
             index=$((index+1))
             scp -r -o StrictHostKeyChecking=no /opt/hadoop-2.7.2 hadoop-slave$index:/opt/
             scp -o StrictHostKeyChecking=no /etc/hosts hadoop-slave$index:/etc/
        done
        ## Add known host
        ssh -o StrictHostKeyChecking=no hadoop-master -t  "exit"

  run_hadoop:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        source /root/.bashrc
        /opt/hadoop-2.7.2/bin/hdfs namenode -format >> /root/run.logs
        /opt/hadoop-2.7.2/sbin/start-dfs.sh >> /root/run.logs
        /opt/hadoop-2.7.2/sbin/start-yarn.sh  >> /root/run.logs

################### Hadoop cluster set ####################

################### ssh key no pawssord auth ####################
  key_add:
    type: OS::Heat::SoftwareConfig
    properties:
      inputs:
        - name: id_rsa_pub
        - name: user_name
      outputs:
        - name: hostname
      group: script
      config: |
        #!/bin/bash
        echo "${id_rsa_pub}" | su - $user_name -c 'tee -a .ssh/authorized_keys'
        hostname > ${heat_outputs_path}.hostname

  key_gen:
    type: OS::Heat::SoftwareConfig
    properties:
      outputs:
        - name: id_rsa_pub
      group: script
      config: |
        #!/bin/bash
        echo -e "\n" | ssh-keygen -t rsa -N "" 
        cat /root/.ssh/id_rsa.pub > ${heat_outputs_path}.id_rsa_pub
################### ssh key no pawssord auth ####################

################### apply ssh key no pawssord auth ####################
  do_key_gen:
    type: OS::Heat::SoftwareDeployment
    properties:
      config:
        get_resource: key_gen
      server:
        get_resource: master_server

  do_key_add:
    type: OS::Heat::SoftwareDeploymentGroup
    properties:
      input_values:
        user_name: root
        id_rsa_pub:
          get_attr: [do_key_gen, id_rsa_pub]
      config:
        get_resource: key_add
      servers:
        get_attr: [slave_cluster, attributes, slave_id]

  do_key_add_master:
    type: OS::Heat::SoftwareDeployment
    properties:
      input_values:
        user_name: root
        id_rsa_pub:
          get_attr: [do_key_gen, id_rsa_pub]
      config:
        get_resource: key_add
      server:
        get_resource: master_server
################## apply ssh key no pawssord auth ####################

################### apply pre_install ####################
  do_slave_pre_install:
    type: OS::Heat::SoftwareDeploymentGroup
    properties:
      config:
        get_resource: pre_install_slave
      servers:
        get_attr: [slave_cluster, attributes, slave_id]

  do_master_pre_install:
    type: OS::Heat::SoftwareDeployment
    depends_on: do_slave_pre_install
    properties:
      input_values:
        master_ip:
         get_attr: [master_server, first_address]
        slave_ip: 
         get_attr: [slave_cluster, attributes, slave_ip]
      config:
        get_resource: pre_install_master
      server:
        get_resource: master_server
################### apply pre_install ####################

################### run Hadoop ####################
  do_run_set_hadoop:
    type: OS::Heat::SoftwareDeployment
    depends_on: do_master_pre_install
    properties:
      input_values:
        slave_ip: 
           get_attr: [slave_cluster, attributes, slave_ip]
      config:
        get_resource: set_hadoop
      server:
        get_resource: master_server

  do_run_set_slaves:
    type: OS::Heat::SoftwareDeployment
    depends_on: do_run_set_hadoop
    properties:
      config:
        get_resource: set_slaves
      server:
        get_resource: master_server

  do_run_hadoop:
    type: OS::Heat::SoftwareDeployment
    depends_on: do_run_set_slaves
    properties:
      config:
        get_resource: run_hadoop
      server:
        get_resource: master_server
################### run Hadoop ####################
  slave_cluster:
    type: OS::Heat::ResourceGroup
    properties:
      count: { get_param: slave_count }
      resource_def:
        type: slave.yaml

  master_server:
    type: OS::Nova::Server
    properties:
      name: hadoop-master
      image:
        get_param: image
      flavor:
        get_param: flavor
      key_name:
        get_param: key_name
      networks:
      - network: {get_param: private_net}
      security_groups: [{ get_param: security_group }]
      user_data_format: SOFTWARE_CONFIG
